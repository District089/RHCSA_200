RHCSA

#Hashwert des Downloads vergleichen

#Windows:
certutil -hashfile rhel-xyz.iso SHA256

#Linux & macOS
shasum -a 256 rhel-xyz.iso

#Virtuelle Konsolen während der Installation (Ctrl+Alt+1, 2, 3, 4, 5, 6)

Console 1 = Hauptfenster, Textnachrichten während der Text Mode Installation und debugging Informationen
Console 2 = Bash Shell um Befehle als root auszuführen
Console 3 = Zeigt Installations Nachrichten und Hardwareinformationen an und speichert diese in /tmp/anaconda.log
Console 4 = Zeigt Speichernachrichten an - /tmp/storage.log
Console 5 = Zeigt Programmnachrichten und Logs an - /tmp/program.log
Console 6 = Standarf Grafische Oberfläche und Installationsbildschirm

#Manuelle Partitionierung

/ (rhel-root-partition) = 10GiB (xfs)  LVM
/boot                   = 1GiB  (xfs)  KEIN LVM (kann auf LVM nicht booten)
/home                   = 1GiB  (xfs)  LVM
/swap                   = 1GiB  (swap) LVM (standard-partition ist auch möglich)

#GUI installieren

yum group install "Server with GUI" -y
systemctl set-default graphical
startx

#Questions:
Kann man RHEL8 im Textmodus noch installieren?
Ja

Auf wieviele Konsolen hat man während des Installationsvorgangs Zugang?
6

Man kann die /boot Partition innerhalb LVM verwenden um RHEL zu booten.
Falsch

Auf welcher kernel Version basiert die erste Version von RHEL 8?
Kernel 4.x

Wie heißen die zwei fast identischen Klone von Red Hat Enterprise Linux?
CentOS und Scientific Linux

Zahlreiche Logdateien werden im /tmp Verzeichnis während des Installationsvorgangs angelegt und aktualisiert. Wohin werden diese Dateien nach der Fertigstellung der Installation verschoben?
/var/log

Wie lautet der Name des RHEL-Installationsprogramms?
anaconda

#Virtuelle Konsolen

STRG+ALT+F1 bis F6 (tty1 - tty6)

Man kann die Anzahl der Konsolen auch verändern in /etc/systemd/logind.conf

Mit "chvt 1-6" kann man die ttys wechseln, falls STRG+ALT+F1-F6 nicht funktioniert


#Archivierung, Komprimierung, Finden und auszuführen

dd if=/dev/zero of=10mb_datei bs=1024 count=10240
du -ms 10mb_datei = Größe überprüfen

gzip 10mb_datei = gezippt
gunzip 10mb_datei = entpackt

gzip -k(1-9 (CPU Leistung und Komprimierungsstärke)) 10mb_datei = entpacken und orig. behalten

gzip -r /Downlods = verpackt nur den Inhalt der einzelnen Dateien im Ordner
gzip -rd /Downlaods = entpacken


#Benutzer Management

useradd -D = Werte anzeigen lassen (Default Settings)
/etc/default/useradd = Ort wo die Einstellungen sind
/etc/login.defs = Konfigurationseinstellungen
/etc/skel = Struktur für ein neues Home Verzeichnis
Bearbeiten in der /etc/passwd mit vipw (vim password)

#Alles was in der /etc/skel gespeichert wird, wird in das Home-Verzeichnis eines neu angelegten Benutzer kopiert!
beim erstellen eines Users wird immer der Inhalt der Datei /etc/skel Komprimierungsstärke


Jeder User muss mindestens einer Gruppe angehörig sein
Gruppen werden in /etc/passwd, gshadow, group verwaltet
Beim erstellen von Dateien werden immer die Primäre Gruppe des Users genommen welche in der /etc/passwd Datei ersichtlich ist
Bearbeiten der /etc/group Datei mit vigr (steht für vim group)
passwd = primäre Gruppenverwaltung
group = sekundäre Gruppenverwaltung

useradd peter

usermod -aG wheel peter

peter id
cat /etc/passwd | grep peter
man sieht, dass Peter nun auch die ID von wheel hat bzw. sich in dieser Gruppe befindet

vigr = man löscht peter aus wheel heraus und nun befindet er sich nicht mehr in der Gruppen
id peter = Beweis

vigr -s = hier aus gshadow auch noch löschen

passwd -S peter = Status abfragen

passwd -i = Anzahl der inaktiven Tage bis zur Sperrung des Kennworts angeben

passwd -l = Konto sperren (lock)
passwd -u = Konto entsperren (unlock)
passwd -d = Konto löschen
passwd -k = abgelaufenes Kennwort reaktivieren

echo "atix" |passwd peter --stdin = Passwort gesetzt

chage -l peter = Informationen abfragen

usermod -l peter2 peter = Peter in Peter2 umbenannt

useradd peter -d /usr/peter -c "kommentar" -s /bin/bash -u 1200
useradd peter -m -c "kommentar" -s /sbin/nologin -u 1300

chage -m 5 -M 8888 -W 5 peter

cat /etc/shadow = Überprüfung

#Erweiterte Datei- und Ordner-Berechtigungen

chmod 777 <datei> oder chown u+rwx,o+rwx,g+rwx

#chgrp wird verwendet um Dateien und Ordnern eine Gruppe zuzuteilen
chgrp root <datei>

#chown wird verwendet um Dateien und Ordnern einem Benutzer zuzuteilen
chown root <datei>

chown dennis:dennis <datei> oder chgrp root:root <datei>


#Netzwerk Management
systemctl status NetworkManager
nmcli = Informationen
nmcli general = mehr Informationen
nmcli radio wifi off/on = automatische WIFI Suche aktivieren/deaktivieren
nmcli con show = verbundene Interfaces
nmcli con edit eth0 = CLI von nmcli starten für die Konfigurationseinstellungen

nmcli> print all
nmcli> print ipv4
nmcli> goto ipv4
nmcli> set addresses 192.168.0.10/24
nmcli> goto dns
nmcli> set dns 1.1.1.1
nmcli> remove addresses
nmcli> save
nmcli> activate

ip route
ip route del default via 192.168.0.1 = default route löschen
ip route add default via 192.168.0.1 = default route hinzufügen

nmcli dev status

nmcli con add con-name ens160 ifname ens160 type ethernet = Damit wird das Interface angelegt
nmcli con edit ens160
goto ipv4
set addresses 192.168.0.220/24
set gateway 192.168.0.1
set dns 1.1.1.1
save
activate

#Software Pakete installieren und aktualisieren

ISO einhängen
mittels lsblk oder df -hT überprüfen

mkdir /mnt
mount /dev/sr0 /mnt
ls /mnt = nun sieht man schon den Inhalt und die Repos der gemounteten ISO
umount /mnt

---------------------------------------------------------------------------
dd if=//dev/sr0 of=/root/repo.iso bs=1M & = wir schicken den Job in den Hintergrund
kill -SIGUSR1 2715  = Um den Fortschritt zu beobachten

Nun ist die ISO auf der Festplatte lokal vorhanden

mkdir /opt/repo
vim /etc/fstab
/root/repo.ISO  /opt/repo iso9660 defaults  0 0
mount -a

ls /opt/repo

Für die Testzwecke alle bisherigen Repos deaktivieren

cd /etc/yum.repos.d/redhat.repo = Alles von Enabled = 1 auf 0 setzen

im Ordner /etc/yum.repos.d/local.repo = erstellen

vim /etc/yum.repos.d/local.repo
[rhel-local-appstream-rpms]
name = Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs) LOCAL
baseurl = file:///opt/repo/AppStream
enabled = 1
gpgcheck = 0
gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
metadata_expire = 86400
enabled_metadata = 0

[rhel-local-baseos-rpms]
name = Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs) BASEOS
baseurl = file:///opt/repo/BaseOS
enabled = 1
gpgcheck = 0
metadata_expire = 86400
enabled_metadata = 0

dnf repolist = ÜBERPRÜFUNG (die angelegten Repos tauchen nun auf)

dnf search <paketname>
dnf provide <paketname>
dnf search </usr/bin/..>
dnf install <paketname>
dnf remove <paketname>
dnf info <paketname>
dnf list <paketname>
dnf update
dnf upgrade
dnf list all
dnf repolist all
dnf config-manager --set-enabled <repositoryname>
dnf config-manager --add-repo <reponame>
dnf updateinfo list available
dnf clean

dnf config-manager --disable <reponame>
dnf config-manager --enable <reponame>
dnf config-manager --set-enabled <reponame>
dnf config-manager --set-disable <reponame>
dnf upgrade --security


#Module
dnf module list
dnf module info <name>
dnf module install <name>
dnf module list --enabled
dnf module list --installed
dnf module list nodejs
dnf module info nodejs
dnf module info nodejs --profile
dnf module list nodejs
dnf module install nodejs:12
dnf module install nodejs:12/development
dnf module reset nodejs:12
dnf module remove nodejs


dnf history
dnf history list all | grep mc
dnf history info 9
dnf history undo 9

#Programmgruppen installieren mit DNF
(Sammlungen von mehreren Paketen, welche ein System bereitstellen z.B. e-Mail Server)
(Es gibt vorgefertigte Gruppen um die Komponenten bereitzustellen)

dnf group summary
dnf group list
dnf group list hidden (zeigt versteckte Gruppen)
dnf group info "Mail-Server"
dnf group install "Mail-Server"
dnf group install "Mail-Server" --with-optional (mit angezeigten Abhängigkeiten)

#RPM Pakete abfragen und anwenden

rpm -qa <paketname> = Liste über alle installierte Pakete
rpm -ql (Liste über den Inhalt eines RPM Pakets)
rpm -qc (Liste über die Konfiguration des RPM Pakets)
rpm -qd (Liste über alle Dokumentationsdateien eines RPM Pakets)
rpm -qR (Liste über die Abhängigkeiten)
rpm -qf (Angewendet auf jede Datei, zeigt das dazugehörige Paket)
rpm -qip (RPM abfragen)
rpm -q --whatrequires
rpm -q --whatprovides
rpm qi zip = Informationen

#RPM installieren, löschen und extrahieren

rpm -i = installieren
rpm -F = bestehendes Paket upgraden
rpm -U = upgraded oder installiert ein Paket falls nicht vorhanden
--force = installiert wenn schon installiert
--replacepkgs = überschreibt existierendes Paket
rpm -h = zeigt Fortschritt an
rpm -v = zeit Details während Installation an
rpm -e = löscht ein paket
--import = importiert einen Public-KEY
rpm -K = überprüft Signatur und Integrität eines Pakets
rpm -Vf = überprüft die Integrität einer installierenden Datei
rpm -Vv = überprüft die Inegrität aller installierten DAteien

rpm -ivh = Paket inkl.Details und Fortschrittbalken installieren
rpm -e <paket> = paket löschen
rpm Uvh = Upgrade inkl. installation falls nicht vorhanden
rpm -Fvh = Upgrade funktioniert nur falls das Paket schon vorhanden bzw. installiert ist
rpm -qlp = Inhalt anzeigen des rpm Pakets
rpm2cpio <paketname> |cpio -id

#RPM Pakete auf Inegrität und GPG Keys überprüfen

rpm -K --nosignature <paket.rpm>
rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat release

um die Signatur überprüfen zu können benötigen wir den GPG-KEY

rpm -q gpg-pubkey = pub-key von gpg-key abfragen
rpm -qi <gpg-key>
ls -la /etc/audit/audit.rules
rpm -Vf /etc/audit/audit.rules = keine Ausgabe, da die Integrität stimmt
chown dennis:dennis /etc/audit/audit.rules
rpm -Vf /etc/audit/audit.rules = nun die Ausgabe, dass etwas nicht mehr stimmt

#verdächtige RPM überprüfen
rpm -qp --scripts python36-

#Die Paket-Datenbank befindet sich im /var/lib/rpm Verzeichnis

[root@dennis ~]# rpm -qf /bin/bash
bash-4.4.20-1.el8_4.x86_64

#Wiederkehrende Aufgaben - Cronjobs

* Minute (0-59)
* Stunde (0-23)
* Tag (1-31)
* Monat (1-12)
* Wochentag (0-7, Sonntag is 0 oder 7)

0 5 * * 1,4 /bin/bash/backup.sh # Mo,Do um 5 Uhr in der Früh wird das Backup ausgeführt

# System Cronjobs werden gespeichert in /etc/cron*
# Benutzer Cronjobs werden gespeichert in /var/spool/cron/
# Zugriff der Benutzer beschränken mit /etc/cron.allow und /etc/cron.deny
  # Wenn die Datei /etc/cron.allow vorhanden ist, müssen Benutzer die Cron verwenden wollen
    eingetragen werden. Standardmäßig gibt es diese Datei nicht und alle dürfen cron verwenden,
    mit Ausnahme von Benutzern die in cron.deny eingetragen sind.

# Wenn beide Dateien vorhanden sind, hat /etc/cron.allow Vorrang und deny wird nicht
berücksichtigt. Der Benutzer muss in cron.allow sein um crontab benutzen zu dürfen

#man crontab /  man 5 crontab


crontab -l = listet alle eingetragenen cronjobs auf
crontab -l -u student = benutzer spezifische Abfrage


[root@dennis ~]# cat /etc/crontab
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root

# For details see man 4 crontabs

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed


crontab -e = cronjob Bearbeiten

tail /var/log/cron = log

journalctl -u crond.service = log

export EDITOR=nano = bei crontab -e wird nun automatisch nano statt vim geöffnet

man k -crontab

crontab -r = cronjob bzw. crontab löschen

#verstehen von anacron = ausgelegt für systeme welche nicht dauerhaft laufen
anacron versteht beim systemstart, dass der job fehlt bzw. nicht ausgeführt wurde und holt dies nach
(arbeitet mit Zeitstempel)
bei cronjobs hingegen wird der job nicht ausgeführt zu der Zeit als der Rechner aus ist udn auch nicht nachgeholt
anacron zu finden in /etc/anacrontab

[root@dennis ~]# cat /etc/anacrontab
# /etc/anacrontab: configuration file for anacron

# See anacron(8) and anacrontab(5) for details.

SHELL=/bin/sh
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
# the maximal random delay added to the base delay of the jobs
RANDOM_DELAY=45
# the jobs will be started during the following hours only
START_HOURS_RANGE=3-22

#period in days   delay in minutes   job-identifier   command
1	5	cron.daily		nice run-parts /etc/cron.daily
7	25	cron.weekly		nice run-parts /etc/cron.weekly
@monthly 45	cron.monthly		nice run-parts /etc/cron.monthly

ls /var/spool/anacron

#einmalig geplante Aufgaben mit AT


systemctl status atd crond = Status Abfrage

at -l = job auflisten


#SystemD Timers

OnBootSec=5min = erste Ausführung 5 Minuten nach Beginn des Bootvorgangs
OnUnitActiveSec=10min = weitere Ausführungen jeweils nach 10 Minuten

systemctl list-unit-files --type=timer
systemctl list-timers

root@dennis lib]# systemctl cat dnf-makecache.timer
# /usr/lib/systemd/system/dnf-makecache.timer
[Unit]
Description=dnf makecache --timer
ConditionKernelCommandLine=!rd.live.image
# See comment in dnf-makecache.service
ConditionPathExists=!/run/ostree-booted
Wants=network-online.target

[Timer]
OnBootSec=10min
OnUnitInactiveSec=1h
RandomizedDelaySec=60m
Unit=dnf-makecache.service

[Install]
WantedBy=timers.target

[root@dennis lib]# systemctl status dnf-makechace.service
Unit dnf-makechace.service could not be found.
[root@dennis lib]# systemctl status dnf-makecache.service
● dnf-makecache.service - dnf makecache
   Loaded: loaded (/usr/lib/systemd/system/dnf-makecache.service; static; vendor preset: disabled)
   Active: inactive (dead) since Sat 2022-01-08 10:26:27 CET; 34min ago
  Process: 402958 ExecStart=/usr/bin/dnf makecache --timer (code=exited, status=0/SUCCESS)
 Main PID: 402958 (code=exited, status=0/SUCCESS)

Jan 08 10:26:24 dennis.rhel systemd[1]: Starting dnf makecache...
Jan 08 10:26:25 dennis.rhel dnf[402958]: Updating Subscription Management repositories.
Jan 08 10:26:27 dennis.rhel dnf[402958]: Metadata cache refreshed recently.
Jan 08 10:26:27 dennis.rhel systemd[1]: dnf-makecache.service: Succeeded.
Jan 08 10:26:27 dennis.rhel systemd[1]: Started dnf makecache.

[root@dennis lib]# systemd-run --on-calendar '*:0/1' /bin/sh -c "date >> /root/log.txt"
Running timer as unit: run-rceeae505fc684e2da5755e64510a872f.timer
Will run service as unit: run-rceeae505fc684e2da5755e64510a872f.service

[root@dennis ~]# systemctl status run-rceeae505fc684e2da5755e64510a872f.service
● run-rceeae505fc684e2da5755e64510a872f.service - /bin/sh -c date >> /root/log.txt
   Loaded: loaded (/run/systemd/transient/run-rceeae505fc684e2da5755e64510a872f.service; transient)
Transient: yes
   Active: inactive (dead) since Sat 2022-01-08 11:04:02 CET; 55s ago
  Process: 405227 ExecStart=/bin/sh -c date >> /root/log.txt (code=exited, status=0/SUCCESS)
 Main PID: 405227 (code=exited, status=0/SUCCESS)

Jan 08 11:04:01 dennis.rhel systemd[1]: Started /bin/sh -c date >> /root/log.txt.
Jan 08 11:04:02 dennis.rhel systemd[1]: run-rceeae505fc684e2da5755e64510a872f.service: Succeeded.

systemd-run --on-calendar '*:0/1' --user /bin/sh -c "date >> /root/log.txt"
cd /run/user/0/systemd/transient/
cat run-*

systemctl deamon-reload

systemd-run --on-calendar="2022-01-9 11:16" /bin/sh/ -c "echo 1 >> /root/echo.txt"

#Kontrolldienste und Daemons (SystemD)

systemctl |less = zeigt die aktiven units an (bessere Übersicht)
systemctl --all = alle Prozesse auch inactive und dead

dnf module list
dnf module install nginx


curl http://localhost = funktioniert nicht
systemctl status nginx = ist nicht aktiv deshalb funktioniert kein curl
systemctl start nginx
nun funktioniert auch der curl aufruf

systemctl enable nginx = nginx startet automatisch, wird durch symlink realisiert
systemctl restart/reload = nach konfig änderung neustarten
systemctl reload-or-restart = reload ist besser um verbindungen aktiv zu halten falls er nicht funktioniert dann restart
systemctl is-active

systemctl is-active
systemctl is-active sshd
systemctl is-enabled sshd
systemctl is-failed nginx

/usr/lib/systemd/system = Hier liegen vordefinierte SystemD Dateien (nicht editieren)
/etc/systemd/system = Der Platz für selbst angelegte Unit-Dateien
/run/systemd/system = Für die Laufzeit relevante Units finden sich hier

Wenn eine bestehende Unit mit dem editor bearbeitet wird, kopiert man diese zuerst in /etc/systemd/system -->
denn SystemD liest zuerst /etc danach /run und zum Schluss /lib ein

Alternative zum bearbeiten mit der "systemctl edit --full" Funktion

systemd-delta = zeigt an welche KOnfigurationsdateien überschrieben bzw. bearbeitet worden sind

#Unit Types

.service = Diense starten überwachen und stoppen
.device = Gerätedateien anlegen
.mount = Ein und Aushängen von Mountpoints
.automount = auomatisches einhängen
.target = Gruppe von Units definieren
.timer = wiederkehrende Aufgaben (ähnlich cron)
.socket = Verbindungen zwischen Prozessen herstellen
.network = Netzwerke konfigurieren
.path = Service-Units abhängig von Änderungen ausführen

systemctl cat nginx = Zeigt die Konfigurationsdatei auf von /etc/systemd/system/nginx
systemctl show nginx = Zeigt alle Konfigurationsparameter an

systemctl edit --full nginx = mit dem Befehl wird die Datei von /usr/lib/ in /etc/systemd/system/ kopiert und bearbeitet

for i in $(ps ax | grep nginx |awk '{print $1}'); do kill -9 echo $i; done

nano /etc/systemd/system/nginx.service = dort tragen wir Restart=always ein
und starten dem daemon mit "systemctl daemon-reload" neu
nun müssen wir mit systemctl start nginx neu neustarten
ps ax |grep nginx
wir killen die master PID
und wenn wir ps ax | grep nginx eintippen sieht man es werden alle worker bzw. services sofort neu gestartet

systemctl -t socket
systemctl -t mount


systemctl list-unit-files
systemd-delta = Zeigt uns nun die Änderungen der Konfig Datei auf


#SystemD Targets

systemctl get-default = anzeigen in welchem Target wir uns befinden
systemctl set-default multi-user.target = Runlevel 3 ohne GUI wird gesetzt
systemctl isolate graphical.target = wechselt einmalig auf ein neues target zb ins graphical target - runlevel 5
systemctl halt = fährt das system herunter und haltet es an
systemctl poweroff = fährt das system herunter und schaltet es aus
systemctl reboot = das system wird neugestartet
systemctl hybrid-sleep = das system fährt in einen Tiefschlaf

#Der Shutdown Befehl sendet eine Broadcast Message um alle Nutzer welche am system angemeldet sind eine Nachricht zu hinterlassen
shutdown -r now = fährt das system sofort herunter und startet neu
shutdown -h 5 = fährt nach 5 Minuten das system herunter und schaltet sich aus
shutdown -H 10 = fährt nach 10 minuten das system herunter und in den Halt Status

cd /etc/systemd/system
ls multi-user.target.wants/
systemctl list-dependencies multi-user.target

systemctl set-default graphical.target

ls /lib/systemd/system/*.target = zeigt auch noch einmal die Targets an

[root@rhel system]# ls -la runle*
lrwxrwxrwx. 1 root root 15 Dec 10 10:31 runlevel0.target -> poweroff.target
lrwxrwxrwx. 1 root root 13 Dec 10 10:31 runlevel1.target -> rescue.target
lrwxrwxrwx. 1 root root 17 Dec 10 10:31 runlevel2.target -> multi-user.target
lrwxrwxrwx. 1 root root 17 Dec 10 10:31 runlevel3.target -> multi-user.target
lrwxrwxrwx. 1 root root 17 Dec 10 10:31 runlevel4.target -> multi-user.target
lrwxrwxrwx. 1 root root 16 Dec 10 10:31 runlevel5.target -> graphical.target
lrwxrwxrwx. 1 root root 13 Dec 10 10:31 runlevel6.target -> reboot.target


systemctl edit --full multi-user.target

systemd-analyze
systemd-analyze blame

systemd-cgls / systemctl status
systemd-cgtop
systemctl show paketname (z.B. nginx)
systemctl set-property

systemctl set-property nginx.service MemoryLimit=1G
systemctl set-property nginx.service MemoryAccounting=1
[root@rhel ~]# systemctl set-property nginx.service AllowedCPUs=1

systemctl show sshd
systemctl set-property sshd Description="open ssh service daemon"

systemctl show nginx | grep Memory

man systemd-resource-control


[root@rhel multi-user.target.wants]# systemctl mask poweroff.target
Created symlink /etc/systemd/system/poweroff.target → /dev/null.

Bedeutet dass dieser Zustand nicht mehr ausgeführt wird
shutdown = passiert nichts
shutdown -h now = passiert nichts

systemctl unmask poweroff.target = nun würde der shutdown Befehl wieder funktionieren

#SystemD Logging mit JournalD

wird in /var/run geschrieben
/var/run existiert nur im aktuellen Ram und ist nicht persistend
Journal ist strukturiert und indexiert
Suchen im Journal ist rasend schnell
Kann als persistend konfiguriert werden

journalctl --since yesterday
journalctl --since "2020-12-01 10:00" --until "2020-12-01 12:00"

journalctl /sbin/sshd = zeigt das jorunal für sshd

systemctl start nginx
journalctl -u nginx
nun sieht man, dass nginx gestartet worden ist

journalctl --list-boots
journalctl -k = Kernel-Nachrichten

#Hiermit macht man das journal persistent also dauerhaft
mkdir -p /var/log/journal
systemctl restart systemd-journald
ls /var/log/journal

#Überwachung und Verwaltung von Linux-Prozessen und Aufgaben


tail -f /var/log/messages = Neuerungen (Liveüberwachung)

tail -f /var/log/messages & = In den Hintergrund schicken


jobs = zeigt alle Jobs im Hintergrund
fg inkl. ausgegebener NUmmer des jobs Befehl, holt den Job wieder in den VOrdergrund

Für MySql-Dumps mit hohen Datensätzen macht es Sinn diese in den Hintergrund zu schicken

ps ax |grep tail = PID = 81325
kill -9 81325


ps = zeigt eine Liste aller laufenden Prozesse des aktuellen Benutzers an
ps aux = zeigt eine Liste aller Prozesse mit Details zu allen Benutzern an
ps fax = zeigt Prozesse in hierarchischer Folge mit der Zugehörigkeit an
ps -fU <user> = Zeigt alle Prozesse eines bestimmten  Benutzers an
ps L = Liste aller Formatierungen
ps -eo user,pid,cmd  = Lässt sich anhand der liste "ps L" ein eigenes Layout zusammenstellen

Je kleiner die PID desto früher wurde der Prozess neugestartet
PID NR1 ist  das systemd
Prozesse innerhalb von [] sind Kernel Prozessen


D = Deep sleeping
R = Running
I = Idle
T = Traced
Z = Zombie
W = Swap-Speicher ausgelagert
< = höhere Priorität
N = niedrigere Priorität
L = Locked

ps -ep user,pid,tty,cmd = eigenes Layout


cd /proc/1099
ls = Hier liegen die Informationen für die PID

cd /run/ = Hier liegen Prozesse mit fest zugeteiler PID (nützlich für Bash-scripte)

cat /run/sssd.PID
ps aux|grep 970


free -m = Ram/Swap speicher etc.

#SWAPINESS


cat /proc/sys/vm/swapiness
sysctl -w vm.swapiness=30
Permanent: Öffnen Sie /etc/sysctl.conf und setzen vm.swapiness=30
reboot nötig
Wert zwischen 30 und 100. Standart 30 oder 60. Bei 100 wird alles in den SWAP ausgelabert und unter 10 kann es zu abstürzen ausführen


Viel RAM und langsame Festplatte = Niedriege Swapiness 10-30
Viel RAM und schnelle SSD  = Hoher Swapiness 80-90
Wenig Ram und Heim PC = Niedriege Swapiness 10-30 für bessere Reatkionsgeschwindkeit auf ANwendungen


#CPU Auslastunge unter Linux

uptime
w
top

yes >> /dev/null = man sendet ununterbrochen einen yes Befehl welcher die load-average erhöht

mit "w" können wir überprüfen das es wirklich so install

mit kill -9 beenden wir die gestarteteten "yes" Prozesse

killall -9 yes = beendet alle "yes" Prozesse

Im top kann man kill <pid> eintippen

top -c = vollständige Kommando inkl. Pfadangabe
top -d = Wiederholrate in Sekunden
top -b = startet top im Batch Modus


#Prioritäten

Standard ist 0

Bereich -20 bis +19

-20 hat die höchste Priorität (meiste CPU Leistung)
19 hat die niedrigste Priorität (geringste CPU Leistung)

Normale Nutzer können die Prioritäten von 0 bis 19 geben
nur Root Benutzer können mehr


nice = 0

nice -n 19 top = top läuft mit der geringsten Priorität
nice -n -20 top = top läuft mit höchster Priorität

nice (ohne Angabe wird 10 genommen)

renice -10 PID

#Signale verstehen und anwenden


kill,killall,pkill

Strg+Z = -SIGSTOP = Programm im Hintergrund stoppen bzw. pausieren

-SIGTERM beendet den Prozess sauber wird empfohlen

kill -l = zeigt alle Signalbefehle auf

kill 1 SIGHUP = Ende-Beenden der Terminalverbindung
kill 2 SIGINT = Ende-Unterbrechen der Terminalverbindung z.B. Strg+C
kill 3 SIGQUIT = Dump&Ende- Unterbrechen der Terminalverbindung und debuggen
kill 9 SIGKILL = Dump&Ende- Sendet Abbruch und debuggen durch den Kernel
kill 10 SIGUSR1 = Status von dd abfragen (kill -SIGUSR1 PID)
kill 15 SIGTERM = Ende-Standarf bei allen kill Programmen: Abschließen und Beenden
kill 18 SIGCONT = Restart
kill 19 SIGSTOP = Anhalten

yes >> /dev/null
!yes
pkill yes
pgrep yes -l -a (Informationen wie name und PID)

pkill -HUP syslogd
pgrep -uroot -l

#Profilbasiertes Tuning

tuned = Service für Systemkomponenten überwacht Systemeinstellungen dynamisch anhand der Aktivitäten
        überwacht CPU,HDD, Netzwerke
        Kann die I/O Rate der Festplatten, Netzwerkgeräte oder Geschwindigkeit der CPU verändern und energiesparender arbeiten


Vordefinierte Profile von RedHat für Laptop/Desktop (balanced), Storage /rhs-high-troughput) KVM

tuned-admin list  = Zeigt eine Liste aller profile
tuned-adm profile <neuerprofilname> = Setzt das neue Profil
tuned-adm active = zeigt das aktuelle Profil an

systemctl status tuned

[root@rhel ~]# tuned-adm active
Current active profile: virtual-guest

tuned-adm list

tuned-adm profile balanced

#Logging und Protokolle

syslog = veraltet
JournalD = ist schneller und stellt Daten für Rsyslog und syslog-ng zur Verfügung
syslog-ng = Weiterentwicklung von Syslog mit dem Ziel bekannte Schwachstellen zu beheben und mit bezahlter Enterprise Funktion

Rsyslog und JournalD für Linux Standardmäßig installiert

JournalD sammelt alle möglichen Daten die von SystemD verwaltet werden an einem Platz
Alles wird im RAM gespeichert bis zum reboot ausser man stellt journalctl auf persistent um

Log Speicherung erfolgt in /dev/log bzw. /var/log/journal (persistent falls man dieses Verzeichnis anlegt)

Verwendet keine Logrotation, es wird archiviert

nano /etc/systemd/journald.conf = zum Bearbeiten der Config, Speichergröße etc.
#Storage=auto (dann kann das JournalD persistent gemacht werden indem das Verzeichnis erstellt wird)

systemctl list-sockets = hier stehen die journal sockets bzw. speicherorte (dev-log, socket, stdout)

journalctl
journalctl -r = reverse

journalctl -n 20 = die letzten 20 Einträge anzeigen
journalctl -f = Liveüberwachung
journalctl -b = Prozesse des letzten Boot-Prozesses
journalctl -b -1 = letzter boot prozess -2 wäre vorletzter aber dazu müsste zuvor persistent logging eingerichtet werden
journalctl -k = Kernel loggings
journalctl -u nginx = Einträge von nginx
journalctl -p error = error messages anzeigen
journalctl --since today
journalctl --since yesterday
journalctl --sine 2020-04-30 --unit 2020-04-10

journalctl <Tab drücken>
dann kann z.B. _UID 0 ausgewählt werden

journalctl _HOSTNAME=<name>

journalctl -o verbose -u nginx

journalctl -u nginx -o json = den output im json format
journalctl -u nginx -o json-pretty = mehrzeiler

systemctl status systemd-journald = Systemstatus abfragen

journalctl --disk-usage = belegten Speicherplatz angezeigen

journalctl --vacuum-size=500M = komprimieren auf 500MB


Storage Wert kann persistent, volatil oder auto angegeben (volatil nicht persisten in /run/log/journal) Wenn der auto Modus angegeben ist, erkennt er
falls der Ordner angelegt wird um auf persistent umzuschwenken

Um Journald persistent zu machen muss der Ordner /var/log/journal erstellt werden
systemctl restart systemd-journald = um die Änderung aktiv zu schalten
Optional können TMP Dateien angelegt werden

mkdir -p /var/log/journal
systemd-tmpfiles --create --prefix /var/log/journal
systemctl restart systemd-journald

nano /etc/systemd/journald.conf = config

#Rsyslog im Detail

Rsyslog ist mit alten syslog kompatibel

Nachrichten welche von JournalD gesammelt werden stehen auch Rsyslog zur Verfügung
Bezieht die Daten aus Quellen wie z.B. JorunalD, Socket, UDP, TCP, Kernel-Logs, Dateien, Windows Event-Logs


/etc/rsyslog.conf oder /etc/rsyslog.d
Log Dateien werden in /var/log geschrieben

mit dem Befehel "logger" können Nachrichten manuell an rsyslog gesendet werden

nano /etc/rsyslog.conf = dort können z.B. .error Logs auf /var/log umgeleitet bzw. angegeben werden

#Logrotation

Wird von Rsyslog verwendet um Dateien zu komprimieren und archivieren
Stellt fest, dass die Dateien nciht zu groß werden und sich von selbst löschen

ls /etc/cron.daily
nano /etc/cron.daily/logrotate

hier liegt ein logrotate-shell script

in /var/log/ liegen mehrere boot.log-20202002 mit Datum Dateien

nano /etc/logrotate = Konfig Datei

nano /etc/logrotate.d/nginx = nginx konfig zum bearbeiten

#Festplattenverwaltung

#Namensgebung der Festplatten auf unterschiedlichen Schnittstellen

/dev/fdX = Diskettenlaufwerk
/dev/hdaX (hda1) IDE/PATA Schnittstelle
(hdd)
/dev/sdaX (sda1) - SCSI oder SATA Schnittstelle
/dev/vdaX (vda1) - Virtuelles Gerät  VirtIO Treiber
/dev/nvmeXnXpX (nvme0n101) - NVME Schnittstelle
nvme0 - Erster registrierter Schnittstellencontroller
nvme0n1 - Erstes registriertes Gerät
nvme0n1p1 - Erste Partition

nvme0n1     259:0    0   30G  0 disk
├─nvme0n1p1 259:1    0  300M  0 part /boot
├─nvme0n1p2 259:2    0    3G  0 part [SWAP]
└─nvme0n1p3 259:3    0 26.7G  0 part /

ls -l /dev/*

parted /dev/sda
p = Informationen abrufen (Partition-Table)


#Festplattenmanagement

1. Klassische Partitionierung
2. LVM - Logical Volume Manager
   Standard in RHEL
   Bietet mehr Flexibilität wie Snapshots und Größenänderungen
3. Stratis
   Zukünftiger Volume Manager für RedHat (noch neu)
   ZFS/BTRFS Features (Devicemapper, Nur als XFS Format, Pools, Snapshots, Thin Provisioning)
   Stratis Dämon läuft im Userspace, ermöglicht API Zugriff was die Entwicklung vereinfacht
   Multi-Tiered Storage Pool, Pool Monitoring, Rollback

   (Thin Provisioning bedeutet wenn 1TB physisch vorhanden bzw, zugeteilt ist belegt man nicht komplett 1TB sondern nur das was gerade tatsächlich belegt ist)

4. VDO
   Ideal bei Backups oder Virtualisierungscluster
   Deduplikation und Kompression
   (für viele Backups mit den selben Daten geeignet)

5. BTRFS
   Wurde von RedHat ersetzt durch Stratis. Fedora setzt weiterhin auf BTRFS


#MBR vs. GPT

MBR = Master Boot Record
Sitzt im ersten Sektor der Festplatte um max. 512 bytes Boot-Informationen zu speichern
Nur 64 Bytes stehen für die Partitionstabelle zur Verfügung
Basiert auf 32 bit Partitionierung mit einer 512b Datenblock Limitierung
Maximal 4 Partiionen mit nur max 2 TiB Kapazität
Möglichkeit der erweiterten und logischen Partitionen nach 4 Partitionen
Keine Redundanz der Partitionstabelle

GPT = GUID/GPT
64 bit Partitionierung, Platz für 128 Partitionen ohne Größenlimitierung
Protective MBR wird im ersten Sektor geschrieben zwecks Abwärtskompatibilität
Redundanz der Partitionstabelle durch automatisches Backup

MBR
fdisk

GTP
gdisk

MBR und GPT
parted
cfdisk (grafisch)

#Erstellen einer Partition mit "parted"

Nachdem erstellen einer Partition muss noch die Formatierung vorgenommen werden
parted schreibt ein Dateisystem Attribut in die Metadaten, diese können ignoriert werden
Partitionstabelle muss zuerst gesetzt werden auf neue Laufwerke (mklabel gpt  / mklabel msdos für mbr)
Gerätenamen neu einlesen mit udevadm settle (GPT)
partprobe - um den Kernel zu informieren, dass eine neue Partitionstabelle erstellt wurde.
Alternative zum neu-einlesen der Partitionstabelle wäre neustarten.

cat /proc/partitions
lsblk
blkid
(zur Überprüfung ob alles vom Kernel eingelesen wurde)


#MBR

1. lsblk
2. parted /dev/sda
3. print
4. mklabel msdos
5. print (nun sieht man aus GTP ist msdos bzw. MBR geworden)
6. mkpart
7. primary = primary or extended
8. xfs = Filesystemtype
9. 1 = Start
10. 1g = Ende
11. print

(parted) print
Model: ATA VMware Virtual S (scsi)
Disk /dev/sda: 5369MB
Sector size (logical/physical): 512B/512B
Partition Table: msdos
Disk Flags:

Number  Start   End     Size   Type     File system  Flags
 1      1049kB  1000MB  999MB  primary  xfs          lba

12. quit
13. cat /proc/partitions = nun sieht man es gibt die Partition sda1
14. partprobe
15. udevadm settle = um Änderungen an der UID neu einzulesen

#GPT

1. parted /dev/sdb
2. mklabel gpt
3. print
4. mkpart
5. Partition Name = z.B. First
6. FileSystemType = xfs
7. Start = 1
8. End = 1000MiB
9. p

(parted) mkpart
Partition name?  []? First
File system type?  [ext2]? xfs
Start? 1
End? 1000MiB
(parted) p
Model: ATA VMware Virtual S (scsi)
Disk /dev/sdb: 5369MB
Sector size (logical/physical): 512B/512B
Partition Table: gpt
Disk Flags:

Number  Start   End     Size    File system  Name   Flags
 1      1049kB  1049MB  1048MB  xfs          First

10. quit
11. partprobe
13. udevadm settle

#Erstellen und löschen von Partitionen mit gdisk

gdisk -l /dev/sda = z.B. MBR only
gdisk -l /dev/sdb = z.B. GPT present / MBR protective ist bei GPT immer da, das ist für die Abwärtskompatibilität

1. gdisk /dev/sdc
2. o = delete all partitions and creates a new protective MBR
3. p
4. n = new partition
5. Enter
6. Enter
7. +500M
8. L
9. 8300
10. p
11. gdisk -l /dev/sdc
12. partprobe
13. udevatm settle

#Partition löschen
1. gdisk /dev/sdc
2. print
3. d
4. w
5. partprobe
6. udevadm settle
7. cat /proc/partitions = Überprüfung

#Erstellen einer Partition mit fdisk (MBR)

1. fdisk /dev/sdc
2. n = neue Partition
3. p = primär
4. partiton number = 1
5. First Sector = Enter
6. +200M
7. p

#Löschen der Partitonen

fdisk /dev/sdc
d = delete
enter
w
parprobe


#Dateisysteme in RHEL

XFS
  Standardformat in RHEL ist xfs
  Kann vergrößert aber nicht verkleinert werden
  Verzögertes Journaling und Copy on Write um Datenintegrität zu gewährleisten
  Keine Dateimengenbegrenzung, ideal für Große Dateien (bis 8 Exbibyte)
  Deduplizierung mit Reflinks


Ext4
  Bis RHEL6 war ext4 Standard
  ext4 kann vergrößert und verkleinert werden
  ext4 ist Journal basierend um Dateiintegrität zu gewährleisten
  Abwärtskompatibel zu ext2

ZFS und BTRFS im Gespräch aber es wird auf xfs gesetzt


#Partition formatieren und einhängen

mkfs<Tab>
(Auswahl aller mkfs.<> Befehle erscheint)

1. mkfs.xfs /dev/sda1
2. mount /dev/sd1 /mnt
3. df -h
/dev/sda1       947M   39M  909M   5% /mnt
4. mount = überprüfen
5. umount /mnt
6. mount

#nochmal von vorn
1. mount /dev/sda1 /mnt
2. cd /mnt
3. dd if=/dev/urandom if=/test bs=1M count=100
[root@rhel mnt]# dd if=/dev/urandom of=test bs=1M count=100
100+0 records in
100+0 records out
104857600 bytes (105 MB, 100 MiB) copied, 0.484387 s, 216 MB/s
(Damit kann die Geschwindkeit z.B. der Festplatte getestet werden)
4. df -h = man sieht, dass nun mehr Speicherplatz durch das "testfile" belegt ist
5. umount /mnt
target is busy.
6. lsof /mnt = hier sieht man was ist gerade in benutzung bzw. busy oder eingehängt
7. man darf sich auch nicht im /mnt Ordner befinden sonst wird diese auch verwendet
8. umount /mnt

[root@rhel ~]# mount| grep "^/dev"
/dev/nvme0n1p3 on / type xfs (rw,relatime,seclabel,attr2,inode64,logbufs=8,logbsize=32k,noquota)
/dev/nvme0n1p1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,logbufs=8,logbsize=32k,noquota)

(Alles was mit /dev beginnt wird gegrept)

#Automatisiertes Einhängen von Geräten mit fstab

Die /etc/fstab enthält alle Informationen für das automatisierte Einhängen von Geräten
Identifikation der Geräte über unterschiedliche Methoden

Gerätedatei /dev/sdX1, Symlink /dev/disk, UUID oder LABEL
UUID und LABEL sind bei externen Geräten vorzuziehen
SystemD Mounts werden auf der  fstab erzeugt durch systemd-fstab-generator
Änderungen der fstab werrden aktiv mit systemctl daemon-reload

Leerzeichen in der fstab müssen mit /gekennzeichnet werden

1.blkid
2.UUID kopieren
3.nano /etc/fstab
4.mkdir /hdd1 && /hdd2
UUID=e8cd5553-1107-4b4a-9aad-2fb4f52833e3 /                       xfs     defaults        0 0
UUID=6b60016a-8a2b-4886-8491-9a569e0d712c /boot                   xfs     defaults        0 0
UUID=f6e2c729-06ff-4103-9977-c34c2674c8a4 none                    swap    defaults        0 0
/dev/sda1                                 /hdd1                   xfs     defaults        0 0
UUID="9a5264dc-ea83-47ad-9ea3-224a717953dd"     /hdd2             ext4    defaults        0 0
5. mount -a
6. lsblk oder df -h = Überprüfung
7. systemctl daemon-reload
8.


Wichtig! mit lsblk -f = kann man überprüfen welches FileSystem sich auf der Parition befindet
wichtig! Wenn der Mountpoint nicht eingehängt ist wird die Root Partition genommen

Der Labelname kann auch anstatt der UUID oder /dev/sda1 verwendet werden

#Partitionen mit LABEL UND UUID

tune2fs --help
xfs_admin -- help
(mit diesen Befehlen können Partitionen benannt werden)


1. umount /hdd2 (device aushängen)
2. xfs_admin -L Database /dev/sdb1(xfs) = gebe /dev/sdb1 den Namen "Database"
3. tune2fs -L Bilder /dev/sda1(ext4) = gebe /dev/sda1 den Namen "Bilder"

NAME        FSTYPE LABEL    UUID                                 MOUNTPOINT
sda
└─sda1      ext4   Bilder   d5ba9326-5799-4203-8326-89342010615d /hdd1
sdb
└─sdb1      xfs    Database b756babb-5b32-414a-a5dc-df23fc1a2965 /hdd2
4. lsblk -f = Überprüfung
5. df -h = Überprüfung
6. blkid = Überprüfung

#Andere Möglichkeit um devices in die /etc/fstab einzuhängen

1. cd /dev/disk
2. ls -la
drwxr-xr-x.  8 root root  160 Jan 21 12:54 .
drwxr-xr-x. 19 root root 3360 Jan 21 12:51 ..
drwxr-xr-x.  2 root root  980 Jan 21 12:51 by-id
drwxr-xr-x.  2 root root   80 Jan 21 12:55 by-label
drwxr-xr-x.  2 root root   60 Jan 21 12:51 by-partlabel
drwxr-xr-x.  2 root root  140 Jan 21 12:51 by-partuuid
drwxr-xr-x.  2 root root  240 Jan 21 12:51 by-path
drwxr-xr-x.  2 root root  140 Jan 21 12:51 by-uuid
3. ls -la by-label
lrwxrwxrwx. 1 root root  10 Jan 21 13:00 Bilder -> ../../sda1
lrwxrwxrwx. 1 root root  10 Jan 21 13:00 Database -> ../../sdb1


#Geräte mit SystemD statt Fstab mounten

1. systemctl
-.mount                                                                  loaded active mounted   Root Mount
Bilder.mount                                                             loaded active mounted   /Bilder
boot.mount                                                               loaded active mounted   /boot
Database.mount                                                           loaded active mounted   /Database
2. cd /run/systemd/generator/
[root@rhel generator]# ls
 Bilder.mount    'dev-disk-by\x2duuid-f6e2c729\x2d06ff\x2d4103\x2d9977\x2dc34c2674c8a4.swap'   swap.target.requires
 boot.mount       local-fs.target.requires
 Database.mount   -.mount

3. cat Database.mount
# Automatically generated by systemd-fstab-generator

[Unit]
SourcePath=/etc/fstab
Documentation=man:fstab(5) man:systemd-fstab-generator(8)
Before=local-fs.target

[Mount]
Where=/Database
What=/dev/disk/by-label/Database
Type=xfs

4. cd /etc/systemd/system
5. nano Database.mount
[Unit]
Description=DatabaseMount

[Mount]
Where=/Database
What=/dev/disk/by-label/Database
Type=xfs
Options=defaults

[Install]
WantedBy=multi-user.target

6. in der /etc/fstab den Eintrag auskommentieren
7. systemctl daemon-reload
8. ls -la /run/systemd/generator/
9. Nun ist hier der Eintrag verschwunden den fstab hier anlegt
10. systemctl start Database.mount
11. lsblk -f = nun ist sie auf /Database gemountet
12. systemctl enable Database.mount = nun wird nach jedem neustart automatisch gemountet
13. systemctl status Database.mount

root@rhel system]# systemctl list-unit-files -t mount
UNIT FILE                     STATE
-.mount                       generated
Bilder.mount                  generated
boot.mount                    generated
Database.mount                enabled
dev-hugepages.mount           static
dev-mqueue.mount              static
proc-fs-nfsd.mount            static
proc-sys-fs-binfmt_misc.mount static
run-vmblock\x2dfuse.mount     disabled
sys-fs-fuse-connections.mount static
sys-kernel-config.mount       static
sys-kernel-debug.mount        static
tmp.mount                     disabled
var-lib-machines.mount        static
var-lib-nfs-rpc_pipefs.mount  static

#XFS DUMP AND XFSRESTORE

cd /Database
touch 2.conf
echo "hallo Welt" > HW.txt
(beides dummy dateien zum test)

xfsdump -l 0 -f /root/Montag.database.bak /Database
(-l = alles backupen, -f = Zielort)

please enter label for this dump session (timeout in 300 sec)
 -> Montag Database FUll backup

 please enter label for media in drive 0 (timeout in 300 sec)
 -> Backuptape 167


 xfsdump: creating dump session media file 0 (media 0, file 0)
 xfsdump: dumping ino map
 xfsdump: dumping directories
 xfsdump: dumping non-directory files
 xfsdump: ending media file
 xfsdump: media file size 22872 bytes
 xfsdump: dump size (non-dir files) : 544 bytes
 xfsdump: dump complete: 79 seconds elapsed
 xfsdump: Dump Summary:
 xfsdump:   stream 0 /root/Montag.database.bak OK (success)
 xfsdump: Dump Status: SUCCESS

Nun löschen wir zum testen die erstellten Dateien im Database Ordner

Anschließend:

xfsdump -I = für Informationen zum backup wiederherstellen bzw. einspielen

xf[root@rhel ~]# xfsdump -I
file system 0:
	fs id:		b756babb-5b32-414a-a5dc-df23fc1a2965
	session 0:
		mount point:	rhel.test:/Database
		device:		rhel.test:/dev/sdb1
		time:		Mon Jan 24 11:14:01 2022
		session label:	"Montag Database FUll backup"
		session id:	206dfa15-bbf7-494a-88d3-51aa20f2946f
		level:		0
		resumed:	NO
		subtree:	NO
		streams:	1
		stream 0:
			pathname:	/root/Montag.database.bak
			start:		ino 131 offset 0
			end:		ino 133 offset 0
			interrupted:	NO
			media files:	1
			media file 0:
				mfile index:	0
				mfile type:	data
				mfile size:	22872
				mfile start:	ino 131 offset 0
				mfile end:	ino 133 offset 0
				media label:	"Backuptape 167"
				media id:	ebd31eb2-9da4-45e0-b252-0fc0d0210829
xfsdump: Dump Status: SUCCESS

xfsrestore -f /root/Montag.database.bak /Database = Hiermit stellen wir den BackUp auf /Database wieder her

Anschließend sind die Dateien wieder vorhanden

#XFSDUMP greift nicht auf die FSTAB zu

#SWAP

Auslagern von Hauptspeicher (RAM) auf die Festplatte
Kann als eigene Partition oder Datei auf einem bestehendem Dateisystem angelegt werden
HDDs/SSDs/NVMEs sind bedeutend langsamer als der Hauptspeicher
Gute SSDs haben eine Zugriffszeit von 0,05ms (enstspricht 50.000ns)
Die Zugriffszeit vom RAM beträgt 50ns (1000x schneller)
Behebt "out of memory" Probleme, da der Hauptspeicher erweitert wird
Anpassung der Swapiness und des Cache pressure (Dateisystem-Cache)
Swapiness Werte: 0 wenn möglich keinen Swap, 100 verwendet möglich viel swap
Standard 30, Empfohlen 60 am Desktop und 10-30 bei einem Server
Cache Pressure Werte: 0 gibt keinen RAM frei, 100 gibt mehr RAM frei
Standard: 100, Meistens empfohlen: 50

free -h = Übersicht + Werte
swapon --show = Übersicht + Werte

Wir erstellen eine neue SWAP-Partition

parted /dev/sdb
mkpart
swap
linux-swap
Anfang = 1 mehr als das Ende der 1. Parition
Ende = wieviel die Partition vom Gesamtspeicherplatz erhalten soll

mkswap /dev/sdb2
swapon /dev/sdb2

free -h = es ist mehr swap geworden
swapon --show = es ist die neue Partition dazugekommen

unter /etc/fstab wird nun swap unter swap gemountet statt einem Ordner

UUID=3ab53aa0-081f-4f9f-998e-b228852b9f56 swap         	          swap 	  defaults     	  0 0

#Wir erstellen ein SWAP-FILE statt einer Partition zusätzlich zu Partition aber auch möglich
fallocate -l 1G /swapfile
chmod 600 /swapfile
mkswap /swapfile
swapon /swapfile

/swapfile                                 swap 	                  swap 	  defaults     	  0 0

#Zur Information
[root@rhel /]# cat /proc/sys/vm/swappiness
50

[root@rhel /]# cat /proc/sys/vm/vfs_cache_pressure
100

[root@rhel /]# sysctl vm.swappiness=10
vm.swappiness = 10

[root@rhel /]# sysctl vm.vfs_cache_pressure=50
vm.vfs_cache_pressure = 50

(beides nur bis zum nächsten reboot)

Dauerhaft machen:

vim /etc/sysctl.conf

vm.swappiness=10
vm.vfs_cache_pressure=50

(beides eintragen dann dauerhaft)

#SWAP und Partitionen löschen

umount /Database /Bilder = unmounten

swapoff /dev/sdb2 = SWAP Partition unmounten
swapoff /swapfile = falls eine Datei statt Partition verwendet wurde
free -h = zur Kontrolle

Partitionen löschen:

parted
rm 1
quit
--------------
Über parted kann man per "t" die Formatierung ändern z.B. Code 82 in SWAP


#Professionelle Festplatten-Verwaltung

LVM, Stratis, VDO


Logical Volume Manager:

Physical Volumes (PVs)
Volume Groups (VGs)
Logical Volumes (LVs)
 Linear Volumes
 Raid Volumes
  Raid Level 0, 1, 4, 5, 6
Thinly-provisioned logical volumes
Snapshot volumes
Cache Volumes

Vorteiel:
Flexible Kapazitäten mehrere Festplatten können zu einem LV zusammengefasst werden.
Die Größe der LV kann erweitert bzw. verkleinert werden.
Reallokierung von Daten
Software Raid
Volume Snapshots

Nachteile:
Ausfallgefahr im Striping
Zugriff über Live-CDs

LVM erstellen

1. Partitionieren der Festplatte mittels parted oder fdisk
2. Erstellen eines Physical Volumes mit pvcreate
3. Erstellen einer Volume Group mit vgcreate
4. Erstellen eines logischen Volumes aus der Volume Group heraus
5. Formatieren des Logischen Volumes mkfs.xfs oder mkfs.Ext
6. Automatisches mounten mittels /etc/fstab



#Mit parted:

parted /dev/sdb
mklabel gtp
(parted) mkpart
Partition name?  []? LVM1
File system type?  [ext2]? xfs
Start? 1
End? 1G
(parted) p

(parted) set 1 lvm on

(parted) p
Model: ATA VMware Virtual S (scsi)
Disk /dev/sdb: 10.7GB
Sector size (logical/physical): 512B/512B
Partition Table: gpt
Disk Flags:

Number  Start   End     Size   File system  Name  Flags
 1      1049kB  1000MB  999MB  xfs          LVM1  lvm

#mit fdisk:

fdisk /dev/sdc

Command (m for help): n
Partition number (1-128, default 1):
First sector (34-10485726, default 2048):
Last sector, +sectors or +size{K,M,G,T,P} (2048-10485726, default 10485726): +1G

Created a new partition 1 of type 'Linux filesystem' and of size 1 GiB.
Partition #1 contains a xfs signature.

Do you want to remove the signature? [Y]es/[N]o: Y

The signature will be removed by a write command.

dann mit "t" den Partitionstyp ändern
31 = lvm
w

1.pvcreate /dev/sdb1
1.pvcreate /dev/sdc1


[root@rhel ~]# pvs
  PV         VG Fmt  Attr PSize PFree
  /dev/sdb1     lvm2 ---  1.00g 1.00g
  /dev/sdc1     lvm2 ---  1.00g 1.00g

  [root@rhel ~]# pvdisplay
    "/dev/sdb1" is a new physical volume of "1.00 GiB"
    --- NEW Physical volume ---
    PV Name               /dev/sdb1
    VG Name
    PV Size               1.00 GiB
    Allocatable           NO
    PE Size               0
    Total PE              0
    Free PE               0
    Allocated PE          0
    PV UUID               ZKoPRm-40F6-BPMv-uMhV-IsvO-un7n-6p9iGd

    "/dev/sdc1" is a new physical volume of "1.00 GiB"
    --- NEW Physical volume ---
    PV Name               /dev/sdc1
    VG Name
    PV Size               1.00 GiB
    Allocatable           NO
    PE Size               0
    Total PE              0
    Free PE               0
    Allocated PE          0
    PV UUID               q2Wmup-IZKi-Lk5Y-RV7A-r19z-uG0V-VLVo8Z

2. vgcreate vg0 /dev/sdb1 /dev/sdc1
   Volume group "vg0" successfully created
3. vgextend vg0 /dev/sdc1 = pv zu vg hinzufügen

   [root@rhel ~]# vgs
     VG  #PV #LV #SN Attr   VSize VFree
     vg0   2   0   0 wz--n- 1.99g 1.99g

   [root@rhel ~]# vgscan
       Found volume group "vg0" using metadata type lvm2

  [root@rhel ~]# vgdisplay vg0
         --- Volume group ---
         VG Name               vg0
         System ID
         Format                lvm2
         Metadata Areas        2
         Metadata Sequence No  1
         VG Access             read/write
         VG Status             resizable
         MAX LV                0
         Cur LV                0
         Open LV               0
         Max PV                0
         Cur PV                2
         Act PV                2
         VG Size               1.99 GiB
         PE Size               4.00 MiB
         Total PE              510
         Alloc PE / Size       0 / 0
         Free  PE / Size       510 / 1.99 GiB
         VG UUID               fmqzmf-xk26-CSeL-1rnc-0Gaq-QZlE-fewDUc


3. lvcreate -n vol_projekte -L 1G vg0
4. lvcreate -n vol_backup -l 100%FREE vg0

[root@rhel ~]# lvs
  LV           VG  Attr       LSize    Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  vol_backup   vg0 -wi-a----- 1016.00m
  vol_projekte vg0 -wi-a-----    1.00g

  [root@rhel ~]# pvs
    PV         VG  Fmt  Attr PSize    PFree
    /dev/sdb1  vg0 lvm2 a--  1020.00m    0
    /dev/sdc1  vg0 lvm2 a--  1020.00m    0

  [root@rhel ~]# vgs
      VG  #PV #LV #SN Attr   VSize VFree
      vg0   2   2   0 wz--n- 1.99g    0

5. mkfs.xfs /dev/vg0/vol_projekte
6. mkfs.ext4 /dev/vg0/vol_backup

[root@rhel ~]# mkdir /lvm/vol_projekte
[root@rhel ~]# mkdir /lvm/vol_backup

mount /dev/vg0/vol_backup /lvm/vol_backup
mount /dev/vg0/vol_projekte /lvm/vol_projekte

#LVM erweitern

Partitionieren einer weiteren Festplatte mit parted oder fdisk
Erstellen eines Physical Volumes mittels pvcreate
Erweitern der Volume Group mit vgextend
Bestehendes Logisches Volume erweitern mit lvextend
Dateisystem resize des logischen Volumes mit resize2fs oder xfs_grow

[root@rhel ~]# vgextend vg0 /dev/sda2
  Volume group "vg0" successfully extended
[root@rhel ~]# pvscan
  PV /dev/sda1   VG vg0             lvm2 [1020.00 MiB / 0    free]
  PV /dev/sdb1   VG vg0             lvm2 [1020.00 MiB / 0    free]
  PV /dev/sda2   VG vg0             lvm2 [1020.00 MiB / 1020.00 MiB free]
  PV /dev/sdb2                      lvm2 [1022.98 MiB]
  Total: 4 [<3.99 GiB] / in use: 3 [<2.99 GiB] / in no VG: 1 [1022.98 MiB]
[root@rhel ~]# vgextend vg0 /dev/sdb2
  Volume group "vg0" successfully extended
[root@rhel ~]# pvscan
  PV /dev/sda1   VG vg0             lvm2 [1020.00 MiB / 0    free]
  PV /dev/sdb1   VG vg0             lvm2 [1020.00 MiB / 0    free]
  PV /dev/sda2   VG vg0             lvm2 [1020.00 MiB / 1020.00 MiB free]
  PV /dev/sdb2   VG vg0             lvm2 [1020.00 MiB / 1020.00 MiB free]
  Total: 4 [3.98 GiB] / in use: 4 [3.98 GiB] / in no VG: 0 [0   ]

[root@rhel ~]# lvextend -L +1G /dev/vg0/vol_project
    Size of logical volume vg0/vol_project changed from 1.00 GiB (256 extents) to 2.00 GiB (512 extents).
    Logical volume vg0/vol_project successfully resized.

    [root@rhel ~]# resize2fs /dev/vg0/vol_backup
    resize2fs 1.45.6 (20-Mar-2020)
    Filesystem at /dev/vg0/vol_backup is mounted on /lvm/vol_backup; on-line resizing required
    old_desc_blocks = 1, new_desc_blocks = 1
    The filesystem on /dev/vg0/vol_backup is now 520192 (4k) blocks long.


#LVM verkleinern

Das Dateisystem XFS erlaubt nur eine Erweiterung
Das Dateisystem ext4 erlaubt Verkleinerung und Erweiterung mit resize2fs
Um ein Dateisystem zu verkleinern müssen wir die Partition aushängen (umount)
Wenn möglich immer ein Backup der Daten machen vor dem verkleinern
Dateisystemintegrität muss vor dem verkleinern überprüft werden
Mit resize2fs lassen sich die Partitionen verkleinern und vergrößern
Um das Logical Volume zu verkleinern gibt es lvreduce

1. umount /lvm/vol_backup
2. df -h od. lsblk -f = zur Überprüfung ob device ausgehängt ist
3. resize2fs /dev/vg0/vol_backup 1G
4. e2fsck -f /dev/vg0/vol_backup
5. lvreduce -L 1G /dev/vg0/vol_backup (angegeben wird immer die Size welche am Ende benötigt wird)
6. lvs
7. mount /dev/vg0/vol_backup /lvm/vol_backup = wieder einhängen

#Der Device Mapper

Der Device Mapper ist ein Teil des Linux-Kernels
Ein Kernel-Treiber der in ein Framework zur Verwaltung von Datenträgern bietet
Erlaubt die Erzeugung virtueller blockorientierter Geräte
Logische LVM Datenträger werden unter Verwendung des Device-Mappers aktiviert und setzen symbolische
Links mit passenden Namen
Alle Device-Mapper Geräte gfidnen sich unter /dev/dm-*
Verlinukungen der DM Geräte anhand der Namen finden sich unter /dev/mapper

#Webserver

Apache Konfig unter : /etc/httpd/conf oder /etc/apache2/conf
HTML-Dateien unter /var/www/html


systemctl restart httpd oder apachectl reload (Nach veränderter Konfig)

conf.d sind snap-in configs die mitgeladen werden
welcome.conf = ist die standard html Page beim öffnen des Browsers

Der HTML Code für die Standardpage liegt unter /usr/share/httpd/noindex/index.html
Unter /var/www/html/index.html (z.B. "Hallo Welt" schreiben und nun erscheint diese Message im Browser)

apachectl configtest = syntax überprüfen

[root@rhel html]# apachectl configtest
AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using rhel.test. Set the 'ServerName' directive globally to suppress this message
Syntax OK

Wir ändern in der httpd.conf : ServerName localhost oder IP oder FQDN

[root@rhel conf]# apachectl configtest
Syntax OK
[root@rhel conf]#


#Root PW vergessen und zurücksetzen

1. Grub Boot Prozess anpassen (rd.break)
2. Einhängen der Festplatte (mount)
3. SELinux Labels beachten (autorelable)
4. Abmelden und neustarten

Im Bootmenü auf einen "Kernel-Eintrag" "e" drücken

Auf der Zeile "Linux..." "end" drücken und ans Ende der Zeile "rd.break" schreiben
Mit "strg +x" beenden

switch_root:/# mount -o remount,rw /sysroot
switch_root:/# chroot sysroot
switch_root:/# passwd
switch_root:/# touch /.autorelabel
exit
exit



























#Kernel Verwaltung

Kernel installieren, updaten
Kernel Module anzeigen, aktivieren und deaktivieren
Kernel Parameter anpassen und verstehen

1. Kernel ist der Kern vom Linux-System
2. Es empfiehlt sich immer einen neuen Kernel zu installieren anstatt den aktuellen updaten. Damit sind beide kernel aktiv und können im Boot-Modus ausgewählt werden
3. Typischerweise wird ein kernel-Upgrade gemacht um neue Features zu nutzen, Bugs zu beseitigen etc.
4. mit lsmod, modinfo, modprobe, und depmod verwalten wir die Module vom kernel
5. wenn wir "rpm" nutzen für eine Kernel installation nutzen Sie immer -i anstelle von -U um einen neuen Kernel zu installieren und nicht den bestehenden zu updaten.
   Damite haben Sie die Möglichkeit auch vom alten Kernel zu Booten, sollte etwas nicht funktionieren

uname -r
uname -a
cat /proc/version
cat /proc/cmdline

[root@rhel ~]# cat /proc/version
Linux version 4.18.0-348.7.1.el8_5.x86_64 (mockbuild@x86-vm-08.build.eng.bos.redhat.com) (gcc version 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC)) #1 SMP Wed Dec 8 21:51:17 EST 2021
[root@rhel ~]# cat /proc/cmdline
BOOT_IMAGE=(hd0,msdos1)/vmlinuz-4.18.0-348.7.1.el8_5.x86_64 root=UUID=e8cd5553-1107-4b4a-9aad-2fb4f52833e3 ro crashkernel=auto resume=UUID=f6e2c729-06ff-4103-9977-c34c2674c8a4 rhgb quiet

dnf update kernel = es handelt sich um eine installation und kein update
dnf list installed kernel = hier sieht man welcher Kernel gerade installiert ist

Auflisten der kernelmodule mit lsmod oder kmod list
Modulinfotmationen anzeigen lassen mit modinfo
Module aktivieren und deaktivieren mit modprobe
Abhängigkeiten von Modulen mit depmod
Einstellungen zu den Modulen finden sich in /etc/modprobe.d/

lsmod = listet Module inkl. Abhängigkeiten
modinfo <modul> = zeigt Informationen (man kopiert den namen eines Moduls der Ausgabe von lsmod)
modprobe -vr dm_mirror = entfernen mit verbose
modprobe -v dm_mirror= fügt mit verbose wieder das Modul hinzu
depmod = überprüft Abhängigkeiten und zeigt sie an
depmod -a
depmod -n = zeigt inkl alias etc an


#Kernel Prozessinformationen

In /proc findet man aktive Prozessinformationen anhand PID und den aktiven Einstellungen der Module
/proc ist ein eigenes Dateisystem welches direkt vom kernel erzeugt wird
In /proc/sys lassen sich Änderungen am aktiven Kernel vornehmen wie z.B. Swappiness oder Netzwerkeinstellungen

[root@rhel ~]# mount
sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime,seclabel)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
(hier sieht man das vom Kernel erzeugte FileSystem /proc)

cd /proc
(die zahlen sind die PIDs)

ps ax
(hier tauchen sie auf)

cat /proc/cpuinfo
cat /proc/devices
cat /proc/mounts
cd /proc/sys/vm
echo "50" > swappiness

cat /etc/sysctl.conf = dort die persistente swappiness

wenn bei lsmod eine 0 dabei steht im modul dann ist dieses nicht aktiv





# GRUB-Bootloader

Bootmenü ist veränderbar mit der Taste "e(edit)"
GRUB Command Prompt mit Taste "c"
Mit CTRL + X lässt sich nach Anpassung der Bootparameter das System starten

1. load_video = Grafiktreiber werden geladen
2. set gfx_payload=keep = bedeutet überspringe diese Einstellungen und wechsle in den Grafikmodus
3. insmod gzio = Damit wird ein kernelmodul geladen um komprimierte,archivierte Files zu öffnen und bearbeiten
4. linux kernel = Linux-Kernel
5. initrd / initramfs = komprimiertes Archiv für den Systemstart benötigt wird und gemountet
6. SystemD = Die Dienste werden der Reihe nach gestaretet

rhgb quiet = red hat graphical boot = versucht die Boot nachrichten zu verstecken und zeigt einen Ladebalken

Grub - Permanente Konfiguration

Konfigurationsdatei von Grub befindet sich unter /etc/default/grub
Mit grub2-mkconfig lässt sich die Konfiguration aktivieren, beachten Sie hierbei die Angaben für EFI oder BIOS
Die grub.cfg wird automatisch generiert und sollte nicht editiert werden

1. nano /etc/default/grub

GRUB_TIMEOUT=5
GRUB_DISTRIBUTOR="$(sed 's, release .*$,,g' /etc/system-release)"
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT="console"
GRUB_CMDLINE_LINUX="crashkernel=auto resume=UUID=05626784-1ea2-4092-a8d1-82878c172d8f rhgb quiet"
GRUB_DISABLE_RECOVERY="true"
GRUB_ENABLE_BLSCFG=true

(wir haben rhgb quit herausgelöscht)

2. grub2-mkconfig = Um die Änderung aktiv zu machen

Nun müssen wir herausfinden ob es sich um EFI oder BIOS handelt

Hierzu schauen wir in den Ordner /boot/
Falls hier der EFI Ordner leer ist und sich das grub.cfg aber im grub2 Ordner befindet dann haben wir grub2

3. grub2-mkconfig -o /boot/grub2/grub.cfg

Info: das Initram muss mit dem zu bootendem Kernel übereinstimmen


# Booten in ein spezielles Target

Targets sind eine Gruppe von SystemD Unit Dateien
z.B. Emergency, rescue, multi-user, graphical.target
Ändern der Bootparameter um ein bestimmtes Target zu Booten
systemd.unit=emergency.target
Wechseln des Targets nach dem Start mit systemctl isolate multi-user.target

1. Mit systemd.unit=rescue.target eingetragen an die rhgb Stelle
2. In der Emergency Shell kann man zb per systemctl list-units oder systemctl cat sshd aufrufen oder systemctl cat graphical.target
3. systemctl start graphical.target

Reihenfolge:
1. nano /etc/default/grub = Hier Änderungen vornehmen
2. cd /boot/grub2/grub.cfg
3. grub2-mkconfig -o grub.cfg = Nun wir die Konfigurations geschrieben und persistent übernommen

#Open-SSH Verwaltung

OpenSSH besteht aus 3 Paketen:
openssh, openssh-client, openssh-server

OpenSSH kann Tunneling, TCP Port Weiterleitung etc.

Konfiguration für Client: /etc/ssh/ssh_config
Konfiguration für Server: /etc/ssh/sshd_config

scp
sftp
slogin
ssh
ssh-add
ssh-agent
ssh-copy-id
ssh-keygen

Um ssh Port umzubiegen:
# semanage port -a -t ssh_port_t -p tcp #PORTNUMBER
#
#Port 22

#ListenAddress 192.168.110.10
(man kann sich lokal nur auf die genannte Adresse anmelden)

#TCP Wrappers - INFO Lektion (NUR für RHEL 7)

Der TCP Wrapper wurde in RHEL8 durch Firewalld abgelöst

Einrichten ob es einem Client erlaubt ist, sich mit einem Dienst zu verbinden, definiert der TCP Wrapper in Dateien, welche
auch als hosts access-Dateien bezeichnet werden.

/etc/hosts.allow und /etc/hosts.deny - Format:dameon:client (vsftpd: .beispiel.com)
Allow Zugriffe werden bevorzugt und haben gegenüber Deny Vorrang


Plazhalter:

ALL - Kann für die Daemon als auch für die Clients verwendet werden (sshd:ALL)
LOCAL - Verbindungen vom lokalen Netzwerk (sshd:LOCAL)
KNOWN - Wenn Host-Name und Host-Addresse oder der Benutzer bekannt sind.
UNKNOWN - Wenn Host-Name und Host-Addresse oder der Benutzer unbekannt sind.
PARANOID - Wenn Host-Name nicht mit der Host-Addresse übereinstimmt

Beispiel: sshd:192.168.0. EXCEPT 192.168.0.1, 192.168.0.2

Alle Logs zum TCP-Wrapper werden in /var/log/secure gespeichert

#SSH-Schlüsselanmeldung

ssh-keygen
ssh-keygen -t rsa -b 1024
cd .ssh
authorized_keys  id_rsa  id_rsa.pub

ssh-copy-id -i id_rsa.pub root@192.168.92.135

tail /var/log/secure
Log für ssh-Anmeldungen


#SCP

Von Lokal auf Remote:
scp lokal.txt root@192.168.92.136:/root/
scp lokal.txt dennis:/root

Von Remote auf Lokal:
scp dennis:/root/remote.txt .
scp root@192.168.92.136:/root/remote.txt .

#SFTP

sftp dennis oder sftp <IP>

get sftp.txt = wir nehmen die Datei vom Zielsystem auf unseres

progress = Fortschrittsbalken für größere Dateien anzeigen

get -R sftp = Den Ordner "sftp" ziehen.


#Befehle remote über SSH ausführen

ssh <Benutzer> ls -la
ssh <Benutzer> cat /etc/hosts
ssh <Benutzer> 'ls -la /root > lsla.txt'
ssh <Benutzer> 'ls -la /root ; ls -la /root'


#Rsync über SSH

Mit rsync lassen sich Ordner und Dateien abgleichen und Synchronisieren

Wenn bei der Quelle und Ziel die Datei existiert werden nur die Änderungen Synchronisiert

Rsync benutzt das SSH Protokoll um eine sichere Übertragung zu gewährleisten und komprimiert standardmäßig auch die Daten
um Transfervolumen zu sparen

Rsync bietet viele Optionen und lassen sich gut in Bash Scripte verwenden und anpassen
Rsync können Sie auch lokal verwenden um z.B. Backups auf externe Geräte zu sichern
Kann auch ACLs (-A) und SELinux Content (-X) synchronisieren

rsync -a /boot/grub2 /backup/
rsync -avz /boot/grub2 root@192.168.92.136:/root/backup
rsync -avzAX /home/rene root@192.168.92.136:/backup = hiermit werden acls und selinux übernommen
rsync -avzAX --numeric-ids /home/rene root@192.168.92.136:/backup



#Automatische Installation Kickstart

Eine Kickstart Datei definiert die Einstellung für eine Installation und kann von hand geschrieben werden oder über das GUI basierte "system-config-kickstart-tool"

Eine Konfigurationsdatei für Kickstart wird bei der Installation des Betriebssystems automatisch abgelegt unter /root/anaconda-ks.cfg

Kickstart-Dateien können von Wechselmedien, Festplatte oder einem Netz-server gebootet werden


Wir legen die Kickstart-Datei bspw. auf einen Webserver unter /var/www/
curl 192.168.92.135/ks.cfg

Wir legen eine neue VM an mit der RHEL8 ISO
Im BootMenu drücken wir "esc" und starten mit folgendem Befehl die Kickstart_Datei

linux ks=http://192.168.92.135


Kickstart Quellen:

DVD-Laufwerk = ks=cdrom:/directory/ks.cfg
Festplatte = ks=hd:/device/ks.cfg
Anderes Laufwerk = ks=file:/device/ks-cfg
HTTP-Server = ks=http://server.mydomain.com/directory/ks.cfg
HTTPS-Server = ks=https://server.mydomain.com/dirctory/ks.cfg
FTP-Server = ks=ftp://server.mydomain.com/directory/ks.cfg
NFS-Server = ks=nfs:server.mydomain.com:/directory/ks.cfg


#FirewallD


FirewallD stellt das Frontend für nftables oder iptables dar.

Iptables sind alt und nftables sind neu.

Nftables ersetzen iptables und bringen neue Funktionen mit sich.

Der FirewallD Daemon verwaltet Gruppen mithilfe von Entitäten, die Zonen genannt werden.

Konfigurationen geschehen über XML Dateien und dem firewalld-cmd Befehl
Zonen sind Regeln die vorgeben, welcher DAtenverkehr abhängig von der Vertrauensstufe, die Sie im Netzwerk haben zugelassen werden sollen
Einzelne Ports lassen sich spezifisch freigeben oder blocken
Permanente Regeln können mit --permanent übernommen werden

man firewall-cmd

[root@test ~]# firewall-cmd --state
running

[root@test ~]# firewall-cmd --get-default-zone
public

[root@test ~]# firewall-cmd --get-active-zone
docker
  interfaces: docker0
public
  interfaces: ens160

[root@test ~]# firewall-cmd --list-all
public (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens160
  sources:
  services: cockpit dhcpv6-client ssh
  ports:
  protocols:
  forward: no
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

root@test ~]# firewall-cmd --list-all-zones | less

[root@test ~]# firewall-cmd --get-zones
block dmz docker drop external home internal libvirt nm-shared public trusted work

[root@test ~]# firewall-cmd --get-services = Hier sieht man die ganzen xml Dateien (Sie liegen unter /usr/lib/firewalld/services/)

[root@test ~]# cat /usr/lib/firewalld/services/http.xml
<?xml version="1.0" encoding="utf-8"?>
<service>
  <short>WWW (HTTP)</short>
  <description>HTTP is the protocol used to serve Web pages. If you plan to make your Web server publicly available, enable this option. This option is not required for viewing pages locally or developing Web pages.</description>
  <port protocol="tcp" port="80"/>
</service>

[root@test ~]# firewall-cmd --zone=public --add-service=http
success
[root@test ~]# firewall-cmd --zone=public --add-service=https
success

[root@test ~]# firewall-cmd --list-services
cockpit dhcpv6-client http https ssh

firewall-cmd --reload = nun ist der Service wieder verschwunden, da wir nicht permanent eingerichtet haben

[root@test ~]# firewall-cmd --zone=public --add-service=https --permanent
success
[root@test ~]# firewall-cmd --zone=public --add-service=http --permanent
success

[root@test ~]# firewall-cmd --runtime-to-permanent
success
Der Befehl macht alle Änderungen anhand des IST-Status permanent

[root@test ~]# firewall-cmd --zone=public --add-port=2050/tcp
success
[root@test ~]# firewall-cmd --zone=public --add-port=2050-2099/udp
success
[root@test ~]# firewall-cmd --zone=public --list-ports
2050/tcp 2050-2099/udp

[root@test ~]# cp /usr/lib/firewalld/services/ssh.xml /etc/firewalld/services/nodejs.xml
[root@test ~]# nano /etc/firewalld/services/nodejs.xml

[root@test ~]# firewall-cmd --zone=public --add-service=nodejs
success

[root@test ~]# firewall-cmd --permanent --new-zone=webpub
success

[root@test ~]# firewall-cmd --permanent --new-zone=webprivate
success

[root@test ~]# firewall-cmd --get-zones
block dmz docker drop external home internal libvirt nm-shared public trusted webprivate webpub work


[root@test ~]# firewall-cmd --zone=webpub --add-service=https
success
[root@test ~]# firewall-cmd --zone=webpub --add-service=http
success
[root@test ~]# firewall-cmd --zone=webpub --add-service=ssh
success

[root@test ~]# firewall-cmd --zone=webpub --list-all
webpub
  target: default
  icmp-block-inversion: no
  interfaces:
  sources:
  services: http https ssh
  ports:
  protocols:
  forward: no
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[root@test ~]# firewall-cmd --zone=webprivate --add-port=8080/tcp
success

[root@test ~]# firewall-cmd --set-default-zone=webpub
success

[root@test ~]# firewall-cmd --get-default-zone
webpub


#SHELL-Scripting

#!/bin/bash

echo "Willkommen $1 in unserer Abteilung!"

./shell.sh Dennis

Dennis wird zu $1

"Willkommen Dennis in unserer Abteilung!"

[root@test ~]# touch for-schleife.sh | xargs chmod +x for-schleife.sh

#!/bin/bash

for ((counter=10; counter>0; counter--))
do
        echo -n "$counter "
done
printf "\n"

echo -n = kein Zeilenumbruch in der Ausgabe!



#!/bin/bash

echo "Geben Sie Ihren Namen an"
read name

if [ $name = "Dennis" ]
then
        echo "Hallo Chef"
else
        echo "Hallo Mitarbeiter"
fi

-eq geht nur bei Integer deshalb wird "=" benutzt in den eckigen Klammern


#!/bin/bash

echo "Geben Sie Ihren Namen an"
read name

if [[ $name = "Dennis" || $name = "Steffi" ]]
then
        echo "Hallo Chef"
else
        echo "Hallo Mitarbeiter"
fi

Hier kann man 2 Werte abfragen z.B. wenn es 2 Chefs gibt, dafür müssen aber auch 2 eckige Klammern benutzt werden


#!/bin/bash

echo "Geben Sie Ihren Namen an"
read name

if [[ $name = "Dennis" || $name = "Steffi" ]]
then
        echo "Hallo Chef"
else
        echo "Hallo Mitarbeiter"
fi

echo "Geben Sie die Personalnummer ein!"
read n

if [[ ( $n -eq 15 || $n -eq 45 ) ]]
then
        echo "Die Zahl stimmt!"
else
        echo "Die Zahl stimmt nicht!"
fi

./schleife.sh 15

#!/bin/bash

counter=$1

while [ $counter -gt 0 ]
do
        echo -n "$counter "
        counter=$(( $counter -1 ))
done


#!/bin/bash

for (( counter=1; counter<=20; counter++ ))
do
        echo -n "$counter "
done


#Dateifreigaben

NFS und Samba-Server installieren und konfigurieren

NFS-Grundlagen:

(Network File System) ist ein Netzwerk-Protokoll um Dateien über das lokale Netzwerk auszutauschen
NFS ist die primäre Linux / Unix Freigaben Methode im GEgensatz zu Samba (SMB)
welches für Windows gedacht ist.

In der Regel ist NFS etwas schneller als SAMBA und eignet sich daher ideal als Freigabe zwischen den Linux Systemen

RPC-Bind wird benötigt für NFSv2 und NFSv3 damit der NFS Client weiß welche Ports benutzt werden vom NFS-Server.
Beim NFSv4 Protkoll ist RPC-Bind teil des Protokolls und wird nicht zusätzlich benögit.

NFS wurde ursprünglich für interne Netzwerke entwickelt. Es bietet von sich einen Mechanismus, um Benutzer zu authentifizieren.
Mit NFSv4 wurde die Möglichkeit der Kerberos-Authentifizierung hinzugefügt.



#NFS Installation
-> Server / Client
-> nfs-server Dienst muss auf dem Server wlaufen welcher den freigegebenen Ordner beinhaltet
-> Freigaben (NFS Shares) werden über die Datei /etc/exports konfiguriert oder mittels Programm exportfs
    -> /freigabeordner host1(optionen), host2 (optionen)
    /nfsfreigabe 192.168.0.10/24 (rw, no_root_squash)
-> no_root_squash - Nur intern verwenden

1. Installation des NFS Server / Client Paketes
2. Ordner definieren oder erstellen der für die Freigabe vorgesehen ist
3. Freigabe definieren in der Exports DAtei und diese neu einlesen
4. Firewall konfigurieren für NFS, MountD, RPC-Bind
5. SELinux Boolean nfs_export_all_rw auf 1 setzen

SERVER:
Auf dem Server ist evtl. schon der NFS-Server installiert
Systemctl status nfs-server
● nfs-server.service - NFS server and services
   Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; disabled; vendor>
   Active: inactive (dead)

systemctl enable --now nfs-server rpcbind

man exports

mkdir /nfsfreigabe
vim /etc/exports
/nfsfreigabe *(rw, no_root_squash)

exportfs -ra

systemctl restart nfs-server
systemctl status nfs-server

[root@test ~]# firewall-cmd --permanent --add-service=nfs
success
[root@test ~]# firewall-cmd --reload
success
[root@test ~]# firewall-cmd --permanent --add-service=mountd
success
[root@test ~]# firewall-cmd --permanent --add-service=rpc-bind
success
[root@test ~]# firewall-cmd --reload
success

[root@test ~]# firewall-cmd --list-all
webpub (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens160
  sources:
  services: mountd nfs rpc-bind ssh
  ports:
  protocols:
  forward: no
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[root@test ~]# sestatus
SELinux status:                 enabled
SELinuxfs mount:                /sys/fs/selinux
SELinux root directory:         /etc/selinux
Loaded policy name:             targeted
Current mode:                   enforcing
Mode from config file:          enforcing
Policy MLS status:              enabled
Policy deny_unknown status:     allowed
Memory protection checking:     actual (secure)
Max kernel policy version:      33

[root@test ~]# semanage boolean -l| grep nfs_
nfs_export_all_ro              (on   ,   on)  Allow nfs to export all ro
nfs_export_all_rw              (on   ,   on)  Allow nfs to export all rw
use_nfs_home_dirs              (off  ,  off)  Allow use to nfs home dirs

(ist schon alles eingestellt)

cd /nfsfreigabe
touch testdatei

#NFS-Freigabe einhängen

Freigaben können neben der export Datei auch mit showmount angezeigt werden
Um ein Ordner vom CLient System aus Einhängen zu können wird ebenfalls der Mount-Befehl benutzt

   -> mount IPAdresse:/freigabeOrdner /lokalerOrdner
   -> mount -t nfs-o optionen host:/freigabeOrdner /lokalerOrdner

Dauerhaftes einbinden via fstab
 -> IPAdresse:/freigabeOrdner /lokalerOrdner nfs _netdev 0 0
(netdev bedeutet, dass erst gemountet wird sobald das Zielsystem auch erreichbar ist)

Optional über Hostname / DNS Auflösung


Client:
dnf search nfs
dnf install nfs-utils

vim /etc/hosts
192.168.92.136 nfs-server
ping nfs-server

mkdir /server1

GOTO Server
[root@test nfsfreigabe]# showmount --exports
Export list for test.rhel:
/nfsfreigabe *

GOTO Client
mount 192.168.92.136:/nfsfreigabe /server1
df -h
cd /server1
touch server1dateivonserver2
GOTOserver
cd /nfsfreigabe
ls
[root@test nfsfreigabe]# ls
freigabe.sh  server1dateivonserver2

umount /server1
vim /etc/fstab
nfs-server:/nfsfreigabe /server1 nfs _netdev 0 0
mount -a

#Samba Server
Ein Samba-Server ermöglicht die Freigabe von Dateien und Druckern zwischen Windows,- und Linux Rechnern

Der Name Samba hat seinen Ursprung beim SMB-Protkoll (Server Message Block), das unter Windows für den netzbasierten Datenaustausch
eingesetzt wird.

Statt SMB wird auch immer wieder vom "Common Internet File System" (CIFS) gesprochen. CIFS ist eine Weiterentwicklung von SMB und wurde
ursprünglich von Microsoft entwickelt

Samba hat eine eigene Benutzerverwaltung und Active Directory etc.

1. Server / Client
2. smb & nmb Dienst muss am Server laufen welcher Freigegebenen Ordner beinhaltet
3. Freigaben  (SMB Shares) erstellen in /etc/samba/smb.conf und Berechtigungen setzen
4. Lokalen Benutzer erstellen und mittels smbpasswd zum SMB hinzufügen
5. Firewall
6. SELinux für Samba (samba_share_t)
7. config überprüfen mit testparm
8. Benutzer editieren / listen mit pdbedit

SERVER1
dnf install samba -y
mkdir /sambafreigabe
adduser -M samba -s /sbin/nologin
chown samba.samba /sambafreigabe/
chmod 755 /sambafreigabe
smbpasswd -a samba
123
123
[root@test ~]# pdbedit -L
samba:1003:
[root@test ~]# systemctl status smb.service nmb.service
[root@test ~]# systemctl enable --now smb nmb
[root@test ~]# firewall-cmd --add-service=samba --permanent
success
[root@test ~]# firewall-cmd --reload
success
[root@test ~]# firewall-cmd --list-all
webpub (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens160
  sources:
  services: mountd nfs rpc-bind samba ssh
  ports:
  protocols:
  forward: no
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

cat /etc/samba/smb.conf.exampe = Zur Hilfe Beispiele für die config
vim /etc/samba/smb.conf
[sambafreigabe]
        path = /sambafreigabe
        guest ok = No
        read only = No
unten an die config hängen

testparm = um den Auszug der config nochmal anzusehen
systemctl restart smb nmb

#Samba Freigaben einhängen
Um eine Samba Freigabe einhängen zu können benötigen wir die cifs-utils und samba-client
-> dnf install samba-client cifs-utils
Auflistung der Samba Freigaben mit dem smbclient
mount -o username=samba //server/sambafreigabe /lokalerOrdner
Dauerhaftes einbinden via fstab
-> //IPAdresse/freigabeOrdner /lokalerOrdner cifs netdev,username=samba,passwd=123 0 0

CLIENT
dnf install -y samba-client cifs-utils
mkdir /sambaOrdner
smbclient -L //samba-server

[root@rhel /]# smbclient -L //samba-server
Enter SAMBA\root's password:
Anonymous login successful

	Sharename       Type      Comment
	---------       ----      -------
	print$          Disk      Printer Drivers
	sambafreigabe   Disk
	IPC$            IPC       IPC Service (Samba 4.14.5)
SMB1 disabled -- no workgroup available
[root@rhel /]# mount -o username=samba,password=123 //samba-server/sambafreigabe /sambaOrdner

mount = Befehl zur Überprüfung
cd /sambaOrdner
touch DateivonSamba

GOTO Server
cd /sambafreigabe
[root@test sambafreigabe]# ls
DateivonSamba

GOTO CLient
#Wir unmounten nun die Freigabe und hängen Sie dauerhaft inder /etc/fstab ein

umount /sambaOrdner
df -h = zur Überprüfung
vim /etc/fstab
//samba-server/sambafreigabe /sambaOrdner cifs _netdev,username=samba,password=123 0 0
mount -a
df -hT

#Info wenn wir auf Server1 setenforce 1 also SELinux aktivieren dann ist keine Berechtigung mehr auf der Freigabe
Also setzen wir setenforce 0
journalctl -r = gibt AUskunft darüber dass SELinux im Weg steht
ODER auf Server 1:
chcon -t samba_share_t /sambafreigabe/Datei = zu holen ist diese Zeile aus /etc/samba/samba.example.config
(muss auf jede sich in der Freigabe befindeten Datei gesetzt werden)

#Automount

Mit autofs lassen sich Partitionen bei Bedarf automatisch einhängen (mounten) und bei längerer Nichtbenutzung auch automatisch wieder Aushängen
Beim Systemstart automatisch statisch ordner einzubinden, ist ein EIntrag in der /etc/fstab notwendig. Mit Autofs werden diese erst dann automaitsch eingehängt, wenn auf sie zugegriffen wird.
Z.B. für Backups  (sobald das Backup gestartet wird mounte das Laufwerk)
Autofs so konfigrueiren, dass eingehänge partitionen nach einer frei wählbaren Zeit automatisch wieder ausgehängt werden, wenn kein Zugriff mehr erfolgt.
Autofs wurde vorrangig zum einhängen von NFS oder SAMBA konzipiert. Auomatisches Einbinden externer Datenträger USB-Sticks / DVDs mit frei wählbaren Optionen-
Verringert gegenüber statischen einhängen die Belastung des Systems, Netzweks und verbessert den Durchsatz.

#Automount installieren

1. Autofs Paket installieren
2. Autofs starten und Autostart setzen (enable)
3. Bearbeiten der auto.master (Hauptkonfigurations Datei)
4. Auf der man Seite zu autofs (man 5 autofs) finden Sie Informationen zum Fortmat der Zuodnungen
5. Die Master DAtei verlinkt auf eine FOrmat Datei wie auto.nfs die dann die enthaltene Mounts beinhaltet für das jeweilige Format
6. Restarten des Autofs nach Änderungen an der Konfigurationsdateien

dnf install autofs -y
systemctl status autofs
systemctl enable --now autofs
ls -l / = mist und root Ordner zum ablegen
cd /
cat auto.master
vim /etc/auto.master
/server1 /etc/auto.nfs = einfügen
vim /etc/auto.nfs
nfsfreigabe nfs-server:/nfsfreigabe
statt nfs-server kann auch IP verwendet werden
ls -l /server1/nfsfreigabe = um darauf zuzugreifen
df -h = nun ist die freigabe gemountet

vim /etc/auto.master
/server1 /etc/auto.nfs --timeout=10
(bedeutet nach 10 sek soll ausgemountet werden)

Aufgabenstellung:
die /etc/hosts bearbeiten auf beiden Seiten
Server1: vim /etc/exports
/nfsbackup 192.168.92.136 (rw,not_root_squash)

mkdir /nfsbackup
systemctl restart nfs-server

Client:
mount srv1:/nfsbackup /server1
funktioniert! nun umount /server1
wir machen einen automount mit auto fs
vim /etc/auto.master
vim /etc/auto.nfs = kann man erstellen falls nicht vorhanden diese Datei legen wir selbst an und ist von vorheriger aufgabe vorhanden
datenbankbackup srv1:/nfsbackup
systemctl restart autofs

Server1:
#Wir erstellen einen Samba User
adduser smbbackup -M -s /sbin/nologin
[root@test ~]# chown smbbackup.smbbackup /smbbackup

[root@test ~]# chmod 755 /smbbackup
[root@test ~]# sestatus
[root@test ~]# chcon -t samba_share_t /smbbackup/
[root@test ~]# smbpasswd -a smbbackup
New SMB password:
Retype new SMB password:
Added user smbbackup.
test123

[root@test ~]# pdbedit -L
samba:1003:
smbbackup:1004:

Server1
vim /etc/samba/smb.conf

[smbbackup]
        path = /smbbackup
        guest ok = No
        read only = No

systemctl restart smb nmb

CLIENT
mount -o username=smbbackup,password=test123 //srv1/smbbackup /server1

zur überprüfung
smbclient -L //srv1
